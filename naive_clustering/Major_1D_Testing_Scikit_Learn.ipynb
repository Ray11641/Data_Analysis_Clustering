{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da6a392",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf418f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Scikit Learn if not installed\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyClustering\n",
    "!pip install pyclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Vector Quantisation\n",
    "!pip install sklvq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self organising maps\n",
    "!pip install sklearn-som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive resonance theory based clustering\n",
    "!pip install art-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b18ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Spectral clustering\n",
    "!pip install pyamg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454532e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ce56b97",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f871ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd() + \"/Data/\"\n",
    "DATA_FILE = \"Data_File.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ef942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR+ DATA_FILE,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.to_numpy()\n",
    "needed_columns = columns[4:]\n",
    "data = df[needed_columns]\n",
    "rows = data.index.to_numpy().astype(str)\n",
    "nSamples = rows.shape[0]\n",
    "columns = data.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e05ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### display data\n",
    "fig= go.Figure(data=go.Heatmap( z=data.to_numpy(), x = columns, y= rows) )\n",
    "\n",
    "#fig = px.imshow(data)\n",
    "fig.update_layout(\n",
    "    width = 600, height = 2400,\n",
    "    autosize = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a91b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c1ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c51b1f2",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "### Algorithms used:\n",
    "#### [1] K-Means [2] Affinity Propagation [3] Mean Shift [4] Spectral Clustering [5] OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1bb381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary copy of dataframe\n",
    "df_temp = df.copy()\n",
    "\n",
    "max_radius = np.max(pairwise_distances(data.to_numpy()))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824374be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.to_numpy() + 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28316a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80038a9d",
   "metadata": {},
   "source": [
    "#### KMeans Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign levels \n",
    "for nClusters in range(2,16):\n",
    "\n",
    "    # Create the bang process\n",
    "    model_instance = KMeans(n_clusters=nClusters, init=\"random\").fit(sample)\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.labels_\n",
    "    #model_noise = model_instance.noise_\n",
    "\n",
    "    df_temp[\"Cluster\"] = model_clusters\n",
    "\n",
    "    if np.unique(model_clusters).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        model_clusters,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output/Scikit_Learn/KMeans/KMeans_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7e1e8",
   "metadata": {},
   "source": [
    "####  Affinity Propagation Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82317d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign levels \n",
    "for damping in np.linspace(0.5,0.99,20):\n",
    "\n",
    "    # Create the bang process\n",
    "    model_instance = AffinityPropagation(damping=damping, random_state=5).fit(sample)\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.labels_\n",
    "    #model_noise = model_instance.noise_\n",
    "\n",
    "    df_temp[\"Cluster\"] = model_clusters\n",
    "\n",
    "    if np.unique(model_clusters).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        model_clusters,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output/Scikit_Learn/Affinity_Propagation/AffinityPropagation_damping_{int(damping*100)}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a48ca4",
   "metadata": {},
   "source": [
    "#### Mean Shift Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for damping in np.linspace(0.01, max_radius, 20):\n",
    "\n",
    "    # Create the bang process\n",
    "    model_instance = MeanShift(bandwidth=damping).fit(sample)\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.labels_\n",
    "    #model_noise = model_instance.noise_\n",
    "\n",
    "    df_temp[\"Cluster\"] = model_clusters\n",
    "\n",
    "    if np.unique(model_clusters).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        model_clusters,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output/Scikit_Learn/MeanShift/MeanShift_bandwidth_{int(damping*100)}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf3097",
   "metadata": {},
   "source": [
    "#### Spectral Clustering Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd005f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nClusters in range(2,20):\n",
    "    # Create the bang process\n",
    "    model_instance = SpectralClustering(n_clusters=nClusters,\n",
    "                                        eigen_solver=\"arpack\",\n",
    "                                        affinity = \"nearest_neighbors\",\n",
    "                                        assign_labels=\"cluster_qr\").fit(sample)\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.labels_\n",
    "    #model_noise = model_instance.noise_\n",
    "\n",
    "    df_temp[\"Cluster\"] = model_clusters\n",
    "\n",
    "    if np.unique(model_clusters).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        model_clusters,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output/Scikit_Learn/Spectral/Spectral_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94284e",
   "metadata": {},
   "source": [
    "#### OPTICS Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nClusters in range(2,7):\n",
    "    # Create the bang process\n",
    "    model_instance = OPTICS(min_samples=nClusters).fit(sample)\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.labels_\n",
    "    #model_noise = model_instance.noise_\n",
    "\n",
    "    df_temp[\"Cluster\"] = model_clusters\n",
    "\n",
    "    if np.unique(model_clusters).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        model_clusters,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        model_clusters)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output/Scikit_Learn/OPTICS/OPTICS_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c9472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
