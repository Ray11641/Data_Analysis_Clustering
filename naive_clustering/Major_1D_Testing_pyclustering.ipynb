{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b10dcc7",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Scikit Learn if not installed\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyClustering\n",
    "!pip install pyclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc84d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Vector Quantisation\n",
    "!pip install sklvq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self organising maps\n",
    "!pip install sklearn-som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive resonance theory based clustering\n",
    "!pip install art-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4619e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6395bc2",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2589cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df54fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getcwd() + \"/Data/\"\n",
    "DATA_FILE = \"Data_File.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DIR+ DATA_FILE,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396473ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.to_numpy()\n",
    "needed_columns = columns[4:]\n",
    "data = df[needed_columns]\n",
    "rows = data.index.to_numpy().astype(str)\n",
    "nSamples = rows.shape[0]\n",
    "columns = data.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1017b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "### display data\n",
    "fig= go.Figure(data=go.Heatmap( z=data.to_numpy(), x = columns, y= rows) )\n",
    "\n",
    "#fig = px.imshow(data)\n",
    "fig.update_layout(\n",
    "    width = 600, height = 2400,\n",
    "    autosize = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c79766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85d5641",
   "metadata": {},
   "source": [
    "## pyclustering\n",
    "\n",
    "### Algorithms used:\n",
    "#### [1] CLARANS, [2] CURE, [3] Expectation Maximisation Algorithm , [4] Genetic Algorithm, [5] Fuzzy C-Means, [6] CLIQUE, [7] BANG, [8] BIRCH, [9] Self Organising Maps, [10] DBSCAN, [11] OPTICS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] BANG \n",
    "from pyclustering.cluster.bang import bang, bang_visualizer\n",
    "\n",
    "# [2] BIRCH\n",
    "from pyclustering.cluster.birch import birch\n",
    "\n",
    "# [3] CLARANS \n",
    "from pyclustering.cluster.clarans import clarans\n",
    "\n",
    "# [4] CLIQUE\n",
    "from pyclustering.cluster.clique import clique, clique_visualizer\n",
    "\n",
    "# [5] CURE\n",
    "from pyclustering.cluster.cure import cure\n",
    "\n",
    "# [6] DBSCAN\n",
    "from pyclustering.cluster.dbscan import dbscan\n",
    "\n",
    "# [7] Expectation Maximisation Algorithm \n",
    "from pyclustering.cluster.ema import ema, ema_visualizer\n",
    "\n",
    "# [8] Fuzzy C-Means\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.fcm import fcm\n",
    "\n",
    "# [9] Genetic Algorithm\n",
    "from pyclustering.cluster.ga import genetic_algorithm, ga_observer\n",
    "\n",
    "# [10] G-Means\n",
    "from pyclustering.cluster.gmeans import gmeans\n",
    "\n",
    "# [10] Self Organising Maps\n",
    "from pyclustering.cluster.somsc import somsc\n",
    "\n",
    "# [11] OPTICS \n",
    "from pyclustering.cluster.optics import optics, ordering_analyser, ordering_visualizer\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_max_scaled = data.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_min_max_scaled.columns:\n",
    "    df_min_max_scaled[column] = (df_min_max_scaled[column]- df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min()) \n",
    "    \n",
    "    \n",
    "df_min_max_scaled    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe66ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### display data\n",
    "fig= go.Figure(data=go.Heatmap( z=df_min_max_scaled.to_numpy(), x = columns, y= rows) )\n",
    "\n",
    "#fig = px.imshow(data)\n",
    "fig.update_layout(\n",
    "    width = 600, height = 2400,\n",
    "    autosize = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70900246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (df_min_max_scaled.to_numpy() + 1e-6).tolist()\n",
    "\n",
    "# Create a temporary copy of dataframe\n",
    "df_temp = df.copy()\n",
    "\n",
    "max_radius = np.max(pairwise_distances(df_min_max_scaled.to_numpy()))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59684abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness_measure = \"Silhouette\"\n",
    "\n",
    "#fitness_measure = \"Calinski\"\n",
    "\n",
    "fitness_measure = \"Davis\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4795da",
   "metadata": {},
   "source": [
    "#### BANG Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7252bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign levels \n",
    "for levels in range(2,30):\n",
    "\n",
    "    # Create the bang process\n",
    "    model_instance = bang(sample,levels)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/BANG/BANG_levels_{levels}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae151aea",
   "metadata": {},
   "source": [
    "#### BIRCH Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 100\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 10\n",
    "\n",
    "num_genes = 2\n",
    "gene_type = [int,[float,4]]\n",
    "gene_space = [{'low': 2, 'high': 12} ,{'low':0.01, 'high':max_radius} ]\n",
    "\n",
    "parent_selection_type=\"sss\"\n",
    "\n",
    "keep_parents = 4\n",
    "\n",
    "crossover_type = \"uniform\"\n",
    "crossover_probability=0.2\n",
    "\n",
    "mutation_type=\"random\"\n",
    "mutation_probability = 0.2\n",
    "mutation_percent_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_BIRCH(solution,solution_idx):\n",
    "    global sample, data, fitness_measure\n",
    "    nClusters = solution[0]\n",
    "    diameter = solution[1]\n",
    "    # Create the bang process\n",
    "    model_instance = birch(sample,nClusters,diameter =diameter)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        fitness = 0\n",
    "    else:\n",
    "        if fitness_measure == \"Silhouette\":\n",
    "            fitness = -silhouette_score(data.to_numpy(),clustering_result,metric='euclidean')\n",
    "        \n",
    "        elif fitness_measure == \"Calinski\":\n",
    "            fitness = -calinski_harabasz_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "        elif fitness_measure == \"Davis\":\n",
    "            fitness = -davies_bouldin_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_BIRCH = pygad.GA(num_generations = num_generations,\n",
    "                               num_parents_mating = num_parents_mating,\n",
    "                               fitness_func = fitness_func_BIRCH,\n",
    "                               sol_per_pop = sol_per_pop,\n",
    "                               num_genes = num_genes,\n",
    "                               gene_type = gene_type,\n",
    "                               gene_space = gene_space,\n",
    "                               parent_selection_type = parent_selection_type,\n",
    "                               keep_parents = keep_parents,\n",
    "                               crossover_type = crossover_type,\n",
    "                               crossover_probability = crossover_probability,\n",
    "                               mutation_type = mutation_type,\n",
    "                               mutation_probability = mutation_probability,\n",
    "                               mutation_percent_genes = mutation_percent_genes,\n",
    "                               parallel_processing = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b64395",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver = []\n",
    "for itr in range(5):\n",
    "    ga_instance_BIRCH.run()\n",
    "\n",
    "    best_solution, best_solution_fitness, best_solution_idx = ga_instance_BIRCH.best_solution()\n",
    "    nClust = best_solution[0]\n",
    "    nNeighbours = best_solution[1]\n",
    "    data_saver.append([nClust,\n",
    "                       nNeighbours,\n",
    "                       best_solution_fitness])\n",
    "data_saver_columns = [\"number of clusters\", \"number of neighbours\",\"Best solution CH index\"]\n",
    "df_data_saver = pd.DataFrame(data_saver,columns = data_saver_columns)\n",
    "\n",
    "if fitness_measure == \"Silhouette\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/BIRCH/BIRCH_SilhouetteIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Calinski\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/BIRCH/BIRCH_CHIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Davis\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/BIRCH/BIRCH_DBIndex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758e359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "500e7fab",
   "metadata": {},
   "source": [
    "#### CLARANS Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 100\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 10\n",
    "\n",
    "num_genes = 2\n",
    "gene_type = [int,int]\n",
    "gene_space = [{'low': 2, 'high': 11} ,{'low':0, 'high':5} ]\n",
    "\n",
    "parent_selection_type=\"sss\"\n",
    "\n",
    "keep_parents = 4\n",
    "\n",
    "crossover_type = \"uniform\"\n",
    "crossover_probability=0.2\n",
    "\n",
    "mutation_type=\"random\"\n",
    "mutation_probability = 0.2\n",
    "mutation_percent_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_CLARANS(solution,solution_idx):\n",
    "    global sample, data\n",
    "    nClusters = solution[0]\n",
    "    neighbours = solution[1]\n",
    "    # Create the bang process\n",
    "    model_instance = clarans(sample,nClusters,10,neighbours)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        fitness = 0\n",
    "    else:\n",
    "        if fitness_measure == \"Silhouette\":\n",
    "            fitness = -silhouette_score(data.to_numpy(),clustering_result,metric='euclidean')\n",
    "        \n",
    "        elif fitness_measure == \"Calinski\":\n",
    "            fitness = -calinski_harabasz_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "        elif fitness_measure == \"Davis\":\n",
    "            fitness = -davies_bouldin_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_CLARANS = pygad.GA(num_generations = num_generations,\n",
    "                               num_parents_mating = num_parents_mating,\n",
    "                               fitness_func = fitness_func_CLARANS,\n",
    "                               sol_per_pop = sol_per_pop,\n",
    "                               num_genes = num_genes,\n",
    "                               gene_type = gene_type,\n",
    "                               gene_space = gene_space,\n",
    "                               parent_selection_type = parent_selection_type,\n",
    "                               keep_parents = keep_parents,\n",
    "                               crossover_type = crossover_type,\n",
    "                               crossover_probability = crossover_probability,\n",
    "                               mutation_type = mutation_type,\n",
    "                               mutation_probability = mutation_probability,\n",
    "                               mutation_percent_genes = mutation_percent_genes,\n",
    "                               parallel_processing = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c74262",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver = []\n",
    "for itr in range(5):\n",
    "    ga_instance_CLARANS.run()\n",
    "\n",
    "    best_solution, best_solution_fitness, best_solution_idx = ga_instance_CLARANS.best_solution()\n",
    "    nClust = best_solution[0]\n",
    "    nNeighbours = best_solution[1]\n",
    "    data_saver.append([nClust,\n",
    "                       nNeighbours,\n",
    "                       best_solution_fitness])\n",
    "data_saver_columns = [\"number of clusters\", \"number of neighbours\",\"Best solution CH index\"]\n",
    "df_data_saver = pd.DataFrame(data_saver,columns = data_saver_columns)\n",
    "\n",
    "if fitness_measure == \"Silhouette\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CLARANS/CLARANS_SilhouetteIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Calinski\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CLARANS/CLARANS_CHIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Davis\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CLARANS/CLARANS_DBIndex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3410c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c89dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ee26f9",
   "metadata": {},
   "source": [
    "#### CLIQUE Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865749da",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "for nIntervals in range(10,100,5):\n",
    "    # Create the CLIQUE process\n",
    "    model_instance = clique(sample,nIntervals,threshold)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CLIQUE/CLIQUE_nIntervals_{nIntervals}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = clique(sample,10,threshold)\n",
    "model_instance.process()\n",
    "cells = model_instance.get_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3940f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38e708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76fd0751",
   "metadata": {},
   "source": [
    "#### CURE Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 100\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 10\n",
    "\n",
    "num_genes = 2\n",
    "gene_type = [int,int]\n",
    "gene_space = [{'low': 2, 'high': 11} ,{'low':1, 'high':5} ]\n",
    "\n",
    "parent_selection_type=\"sss\"\n",
    "\n",
    "keep_parents = 4\n",
    "\n",
    "crossover_type = \"uniform\"\n",
    "\n",
    "crossover_probability=0.2\n",
    "\n",
    "mutation_type=\"random\"\n",
    "mutation_probability = 0.2\n",
    "mutation_percent_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_CURE(solution,solution_idx):\n",
    "    global sample, data\n",
    "    nClusters = solution[0]\n",
    "    nRepresentatives = solution[1]\n",
    "    # Create the bang process\n",
    "    model_instance = cure(sample,nClusters, number_represent_points = nRepresentatives)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        fitness = 0\n",
    "    else:\n",
    "        if fitness_measure == \"Silhouette\":\n",
    "            fitness = -silhouette_score(data.to_numpy(),clustering_result,metric='euclidean')\n",
    "        \n",
    "        elif fitness_measure == \"Calinski\":\n",
    "            fitness = -calinski_harabasz_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "        elif fitness_measure == \"Davis\":\n",
    "            fitness = -davies_bouldin_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_CURE = pygad.GA(num_generations = num_generations,\n",
    "                            num_parents_mating = num_parents_mating,\n",
    "                            fitness_func = fitness_func_CURE,\n",
    "                            sol_per_pop = sol_per_pop,\n",
    "                            num_genes = num_genes,\n",
    "                            gene_type = gene_type,\n",
    "                            gene_space = gene_space,\n",
    "                            parent_selection_type = parent_selection_type,\n",
    "                            keep_parents = keep_parents,\n",
    "                            crossover_type = crossover_type,\n",
    "                            crossover_probability = crossover_probability,\n",
    "                            mutation_type = mutation_type,\n",
    "                            mutation_probability = mutation_probability,\n",
    "                            mutation_percent_genes = mutation_percent_genes,\n",
    "                            parallel_processing = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e267476",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver = []\n",
    "for itr in range(5):\n",
    "    ga_instance_CURE.run()\n",
    "\n",
    "    best_solution, best_solution_fitness, best_solution_idx = ga_instance_CURE.best_solution()\n",
    "    nClust = best_solution[0]\n",
    "    nNeighbours = best_solution[1]\n",
    "    data_saver.append([nClust,\n",
    "                       nNeighbours,\n",
    "                       best_solution_fitness])\n",
    "data_saver_columns = [\"number of clusters\", \"number of neighbours\",\"Best solution CH index\"]\n",
    "df_data_saver = pd.DataFrame(data_saver,columns = data_saver_columns)\n",
    "\n",
    "if fitness_measure == \"Silhouette\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CURE/CURE_SilhouetteIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Calinski\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CURE/CURE_CHIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Davis\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/CURE/CURE_DBIndex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd9b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "789ccb87",
   "metadata": {},
   "source": [
    "####  DBSCAN Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 100\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 10\n",
    "\n",
    "num_genes = 2\n",
    "gene_type = [int,[float,4]]\n",
    "gene_space = [{'low': 2, 'high': 11} ,{'low':0.01, 'high':max_radius} ]\n",
    "\n",
    "parent_selection_type=\"sss\"\n",
    "\n",
    "keep_parents = 4\n",
    "\n",
    "crossover_type = \"uniform\"\n",
    "crossover_probability=0.2\n",
    "\n",
    "mutation_type=\"random\"\n",
    "mutation_probability = 0.2\n",
    "mutation_percent_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4470d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_DBSCAN(solution,solution_idx):\n",
    "    global sample, data\n",
    "    nNeighbours = solution[0]\n",
    "    diameter = solution[1]\n",
    "    # Create the bang process\n",
    "    model_instance = dbscan(sample,diameter,nNeighbours)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        fitness = 0\n",
    "    else:\n",
    "        if fitness_measure == \"Silhouette\":\n",
    "            fitness = -silhouette_score(data.to_numpy(),clustering_result,metric='euclidean')\n",
    "        \n",
    "        elif fitness_measure == \"Calinski\":\n",
    "            fitness = -calinski_harabasz_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "        elif fitness_measure == \"Davis\":\n",
    "            fitness = -davies_bouldin_score(data.to_numpy(),clustering_result)\n",
    "        \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f803d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance_DBSCAN = pygad.GA(num_generations = num_generations,\n",
    "                               num_parents_mating = num_parents_mating,\n",
    "                               fitness_func = fitness_func_DBSCAN,\n",
    "                               sol_per_pop = sol_per_pop,\n",
    "                               num_genes = num_genes,\n",
    "                               gene_type = gene_type,\n",
    "                               gene_space = gene_space,\n",
    "                               parent_selection_type = parent_selection_type,\n",
    "                               keep_parents = keep_parents,\n",
    "                               crossover_type = crossover_type,\n",
    "                               crossover_probability = crossover_probability,\n",
    "                               mutation_type = mutation_type,\n",
    "                               mutation_probability = mutation_probability,\n",
    "                               mutation_percent_genes = mutation_percent_genes,\n",
    "                               parallel_processing = 4\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db34a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver = []\n",
    "for itr in range(5):\n",
    "    ga_instance_DBSCAN.run()\n",
    "\n",
    "    best_solution, best_solution_fitness, best_solution_idx = ga_instance_DBSCAN.best_solution()\n",
    "    nClust = best_solution[0]\n",
    "    nNeighbours = best_solution[1]\n",
    "    data_saver.append([nClust,\n",
    "                       nNeighbours,\n",
    "                       best_solution_fitness])\n",
    "data_saver_columns = [\"number of clusters\", \"number of neighbours\",\"Best solution CH index\"]\n",
    "df_data_saver = pd.DataFrame(data_saver,columns = data_saver_columns)\n",
    "\n",
    "if fitness_measure == \"Silhouette\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/DBSCAN/DBSCAN_SilhouetteIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Calinski\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/DBSCAN/DBSCAN_CHIndex.csv\")\n",
    "    \n",
    "elif fitness_measure == \"Davis\":\n",
    "    df_data_saver.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/DBSCAN/DBSCAN_DBIndex.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f4a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b67585",
   "metadata": {},
   "source": [
    "#### Expectation Maximisation Algorithm Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method uses Gaussian Mixture Model \n",
    "for nClusters in range(2,15):\n",
    "    #print(f\"Iteration nClusters = {nClusters}\")\n",
    "    # Create the bang process\n",
    "    model_instance = ema(sample,nClusters)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/EMA/EMA_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee5cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7db198",
   "metadata": {},
   "source": [
    "#### Fuzzy C-Means Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa29e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "\n",
    "for nClusters in range(2,15):\n",
    "    #print(f\"Iteration nClusters = {nClusters}\")\n",
    "    # Create the bang process\n",
    "    # initialize\n",
    "    initial_centers = kmeans_plusplus_initializer(sample,\n",
    "                                                  nClusters,\n",
    "                                                  kmeans_plusplus_initializer.FARTHEST_CENTER_CANDIDATE).initialize()\n",
    "    model_instance = fcm(sample,initial_centers)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/Fuzzy_C_Means/FCM_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059679ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db21f616",
   "metadata": {},
   "source": [
    "#### Genetic Algorithm Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf24d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method uses Gaussian Mixture Model \n",
    "for nClusters in range(2,15):\n",
    "    #print(f\"Iteration nClusters = {nClusters}\")\n",
    "    # Create the bang process\n",
    "    model_instance = genetic_algorithm(data = sample,\n",
    "                                       count_clusters = nClusters,\n",
    "                                       chromosome_count=100,\n",
    "                                       population_count=200,\n",
    "                                       count_mutation_gens=2)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/GA/GA_nClusters_{nClusters}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfc883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f033fc6d",
   "metadata": {},
   "source": [
    "#### G-Means Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for initClusters in range(2,25):\n",
    "    #print(f\"Iteration nClusters = {nClusters}\")\n",
    "    # Create the bang process\n",
    "    model_instance = gmeans(sample, k_init=1, repeat=10, k_max= initClusters)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/GMeans/GMeans_maxCentres_{initClusters}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee800400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56de0ba1",
   "metadata": {},
   "source": [
    "#### Self Organising Maps Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd539bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nClusters in range(2,15):\n",
    "    #print(f\"Iteration nClusters = {nClusters}\")\n",
    "    # Create the bang process\n",
    "    model_instance = somsc(sample, nClusters)\n",
    "    model_instance.process()\n",
    "\n",
    "    # Obtain clustering results\n",
    "    model_clusters = model_instance.get_clusters()\n",
    "    #model_noise = model_instance.get_noise()\n",
    "\n",
    "    clustering_result = np.zeros(rows.shape)\n",
    "    for itr, clusters in enumerate(model_clusters):\n",
    "        num_cluster = itr+1\n",
    "        for members in clusters:\n",
    "            clustering_result[members]=num_cluster\n",
    "\n",
    "    df_temp[\"Cluster\"] = clustering_result\n",
    "\n",
    "    if np.unique(clustering_result).size<=1.0:\n",
    "        df_temp[\"Silhouette Score\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Davis-Bouldin\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "        df_temp[\"Calinski-Harbasz\"] = [0]+ [\"\"]*(nSamples-1)\n",
    "    else:\n",
    "        df_temp[\"Silhouette Score\"] = [silhouette_score(data.to_numpy(),\n",
    "                                                        clustering_result,\n",
    "                                                        metric='euclidean')] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Davis-Bouldin\"] = [davies_bouldin_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "\n",
    "        df_temp[\"Calinski-Harbasz\"] = [calinski_harabasz_score(data.to_numpy(),\n",
    "                                                        clustering_result)] + [\"\"]*(nSamples-1)\n",
    "        \n",
    "    df_temp.to_csv(f\"Output_Reduced_Dimensions_Normalised/Pyclustering/SOFM/SOFM_nClusters_{nClusters}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad1fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eee53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31db05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580dd6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
